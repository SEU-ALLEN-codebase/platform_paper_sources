{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,glob\n",
    "import json\n",
    "import pickle\n",
    "import copy\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "###from sklearn.cluster import MeanShift\n",
    "###from sklearn.cluster import KMeans\n",
    "###from sklearn.metrics import pairwise_distances\n",
    "from scipy.spatial import distance_matrix\n",
    "from scipy.spatial.distance import cdist\n",
    "import SimpleITK as sitk\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "from matplotlib import cm\n",
    "\n",
    "#from matplotlib.patches import Patch\n",
    "# import hdbscan\n",
    "# import umap\n",
    "\n",
    "from swc_handler import parse_swc\n",
    "\n",
    "# import graphviz\n",
    "# from graphviz import Digraph\n",
    "\n",
    "import networkx as nx\n",
    "from networkx.drawing.nx_pydot import pydot_layout\n",
    "from networkx.drawing.nx_pydot import graphviz_layout\n",
    "from networkx.drawing.nx_pydot import write_dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 function to arrange module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'orange', 1: 'magenta', 2: 'cyan'}\n",
      "{'PC5': 'orange', 'MARN': 'orange', 'DMX': 'orange', 'PRP': 'orange', 'AMB': 'orange', 'PPY': 'orange', 'RPA': 'orange', 'EW': 'orange', 'Pa4': 'orange', 'IV': 'orange', 'MA3': 'orange', 'CLI': 'orange', 'DR': 'orange', 'RPO': 'orange', 'V': 'orange', 'VTN': 'orange', 'AT': 'orange', 'LT': 'orange', 'SLC': 'orange', 'CS': 'orange', 'GPi': 'magenta', 'VTA': 'magenta', 'PPN': 'magenta', 'PSTN': 'cyan', 'RT': 'cyan', 'ZI': 'cyan', 'PeF': 'cyan', 'TU': 'cyan', 'SPA': 'cyan', 'ME': 'cyan', 'PN': 'cyan', 'III': 'cyan', 'MRN': 'cyan'}\n"
     ]
    }
   ],
   "source": [
    "# def get_regions_name_module_dict(ms=[]):\n",
    "#     with open('../../assets/modules.txt','r') as f:\n",
    "#         data = []\n",
    "#         for i,line in enumerate(f.readlines()):\n",
    "#             if (ms) and (i not in ms): continue\n",
    "                \n",
    "#             line = line.strip()\n",
    "#             print(line)\n",
    "#             for region_name in line.split(', '):\n",
    "#                 data.append((region_name,i))\n",
    "    \n",
    "#     new_dict = dict(data)\n",
    "#     return new_dict\n",
    "\n",
    "def get_regions_name_module_dict():\n",
    "    data = []\n",
    "    with open('../../assets/modules.txt','r') as f:\n",
    "        i = 0\n",
    "        for line in f.readlines():\n",
    "            line = line.strip()\n",
    "            region_name = line.split('\\'')[1]\n",
    "            data.append((region_name,i))\n",
    "            if line[-1]==';': \n",
    "                i += 1\n",
    "    new_dict = dict(data)\n",
    "    return new_dict\n",
    "\n",
    "\n",
    "\n",
    "from utils import color_map\n",
    "regions_module_dict = color_map(get_regions_name_module_dict(),\n",
    "                                colors=['orange','magenta','cyan'])\n",
    "                                #colors=['chocolate','orange','yellow','black','blue','cyan','purple','red','magenta']+['white']*6)\n",
    "                                #colors=['white']*9+['orange','yellow','black','blue','purple','magenta'])\n",
    "print(regions_module_dict)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 function to cluster all regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n40 len314 clustering......[0, 1, 2, 5, 5, 5, 6, 7, 8, 10, 10, 12, 12, 13, 16, 16, 16, 18, 18, 21, 21, 21, 27, 27, 27, 27, 27, 27, 34, 34, 34, 34, 34, 34, 34, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 54, 54, 54, 54, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 115, 115, 115, 115, 115, 115, 115, 124, 124, 124, 124, 124, 124, 124, 124, 124, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 192, 192, 192, 192, 192, 192, 192, 193, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 238, 243, 243, 243, 243, 243, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 259, 259, 259, 260, 280, 280, 280, 280, 280, 280, 280, 280, 280, 280, 280, 280, 280, 280, 280, 280, 280, 280, 280, 280, 286, 286, 286, 286, 286, 286, 291, 291, 291, 291, 291, 292, 293, 294, 304, 304, 304, 304, 304, 304, 304, 304, 304, 304, 306, 306, 312, 312, 312, 312, 312, 312, 312] len314......n40......61\n",
      "\n",
      "n42 len314 clustering......[0, 1, 2, 5, 5, 5, 6, 7, 8, 10, 10, 12, 12, 13, 16, 16, 16, 18, 18, 21, 21, 21, 27, 27, 27, 27, 27, 27, 34, 34, 34, 34, 34, 34, 34, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 54, 54, 54, 54, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 115, 115, 115, 115, 115, 115, 115, 124, 124, 124, 124, 124, 124, 124, 124, 124, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 192, 192, 192, 192, 192, 192, 192, 193, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 225, 225, 225, 225, 225, 233, 233, 233, 233, 233, 233, 233, 233, 238, 238, 238, 238, 238, 243, 243, 243, 243, 243, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 259, 259, 259, 260, 280, 280, 280, 280, 280, 280, 280, 280, 280, 280, 280, 280, 280, 280, 280, 280, 280, 280, 280, 280, 286, 286, 286, 286, 286, 286, 291, 291, 291, 291, 291, 292, 293, 294, 304, 304, 304, 304, 304, 304, 304, 304, 304, 304, 306, 306, 312, 312, 312, 312, 312, 312, 312] len314......n42......61\n",
      "\n",
      "n44 len314 clustering......[0, 1, 2, 5, 5, 5, 6, 7, 8, 10, 10, 12, 12, 13, 16, 16, 16, 18, 18, 21, 21, 21, 27, 27, 27, 27, 27, 27, 33, 33, 33, 33, 33, 33, 34, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 54, 54, 54, 54, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 115, 115, 115, 115, 115, 115, 115, 124, 124, 124, 124, 124, 124, 124, 124, 124, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 144, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 185, 192, 192, 192, 192, 192, 192, 192, 193, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 225, 225, 225, 225, 225, 233, 233, 233, 233, 233, 233, 233, 233, 238, 238, 238, 238, 238, 243, 243, 243, 243, 243, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 256, 259, 259, 259, 260, 280, 280, 280, 280, 280, 280, 280, 280, 280, 280, 280, 280, 280, 280, 280, 280, 280, 280, 280, 280, 286, 286, 286, 286, 286, 286, 291, 291, 291, 291, 291, 292, 293, 294, 304, 304, 304, 304, 304, 304, 304, 304, 304, 304, 306, 306, 312, 312, 312, 312, 312, 312, 312] len314......n44......41\n",
      "GPi 87 47\n",
      "VTA 174 169\n",
      "PPN 221 100\n"
     ]
    }
   ],
   "source": [
    "from utils import get_dict, get_u16_u32_id_dict, get_region_name_list\n",
    "def mykmeans(X,n_clusters):  \n",
    "    np.set_printoptions(suppress=True)\n",
    "    X = np.array(X).round(2)\n",
    "    X_internal = X[1:]-X[:-1]\n",
    "    ini_clusters_X_internal_ids_list = sorted(range(len(X_internal)),key=lambda x: X_internal[x],reverse=True)[:n_clusters]\n",
    "\n",
    "    cluster = {}\n",
    "    for ini_cluster_X_internal_id in ini_clusters_X_internal_ids_list:\n",
    "        cluster[ini_cluster_X_internal_id] = [X[ini_cluster_X_internal_id]]      \n",
    "    data = X.tolist()\n",
    "    for k,v in cluster.items():\n",
    "        for d in v:\n",
    "            data.pop(data.index(d))\n",
    "    \n",
    "    while len(data):\n",
    "        data_dist_tomax = []\n",
    "        data_dist_tomin = []\n",
    "        for c in cluster.keys():\n",
    "            [data_dist_tomax.append(abs(d-max(cluster[c]))) for d in data]\n",
    "            [data_dist_tomin.append(abs(d-min(cluster[c]))) for d in data]\n",
    "        min_maxdist = min(data_dist_tomax)\n",
    "        min_mindist = min(data_dist_tomin)\n",
    "        rm_id_dist = data_dist_tomax.index(min_maxdist) if min_maxdist<min_mindist else data_dist_tomin.index(min_mindist)\n",
    "        rm_id = rm_id_dist%len(data)\n",
    "        rm_data = data[rm_id]\n",
    "        rm_c = int(rm_id_dist/len(data))\n",
    "        dc = list(cluster.keys())[rm_c]\n",
    "        cluster[dc].extend([rm_data])                \n",
    "        data.pop(data.index(rm_data))\n",
    "\n",
    "    yhat = []\n",
    "    for x in X:\n",
    "        xc = 0\n",
    "        for c,d in cluster.items():\n",
    "            if x in d:\n",
    "                xc = 1\n",
    "                yhat.append(c)\n",
    "                break\n",
    "        if not xc: raise\n",
    "    return yhat\n",
    "\n",
    "def get_region_range_and_region_cluster(level,uint,axis,n_clusters):\n",
    "    center_dict = get_dict(level,uint,'center')\n",
    "    if not (axis=='DV' and uint==32):\n",
    "        u16_u32_id_dict = get_u16_u32_id_dict()\n",
    "        \n",
    "    raxis = ['AP','DV','RL'].index(axis)\n",
    "    if not (axis=='DV' and uint==32):\n",
    "        rc_list = [(k,v[raxis]) for k,v in center_dict.items() if not np.isnan(v[raxis])]\n",
    "    else:\n",
    "        center_dict2 = get_dict(level,16,'center')\n",
    "        rc_list = [(u16_u32_id_dict[k],v[raxis]) for k,v in center_dict2.items() if (int(k)%2 and (not np.isnan(v[raxis])))]\n",
    "    rc_list.sort(key=lambda x: x[1],reverse=False)\n",
    "    region_list = [r[0] for r in rc_list]\n",
    "    center_list = [r[1] for r in rc_list]\n",
    "    \n",
    "    axis2 = ['RL','AP','DV'][['AP','DV','RL'].index(axis)]\n",
    "    raxis2 = ['AP','DV','RL'].index(axis2)\n",
    "    if not (axis=='DV' and uint==32):\n",
    "        rc_list2 = [(k,v[raxis2]) for k,v in center_dict.items() if not np.isnan(v[raxis2])]\n",
    "    else:\n",
    "        rc_list2 = [(u16_u32_id_dict[k],v[raxis2]) for k,v in center_dict2.items() if (int(k)%2 and (not np.isnan(v[raxis2])))]\n",
    "    rc_list2.sort(key=lambda x: x[1],reverse=False)\n",
    "    region_list2 = [r[0] for r in rc_list2]\n",
    "    center_list2 = [r[1] for r in rc_list2]\n",
    "   \n",
    "    yhat = mykmeans(center_list,n_clusters)\n",
    "    cs,ccs = np.unique(yhat,return_counts=True)\n",
    "    count_max = ccs.max()\n",
    "    print(f'\\nn{n_clusters} len{len(center_list)} clustering......{yhat} len{len(yhat)}......n{len(np.unique(yhat))}......{count_max}')\n",
    "    while count_max > n_clusters:\n",
    "        n_clusters += 2 \n",
    "        yhat = mykmeans(center_list,n_clusters=n_clusters)\n",
    "        cs,ccs = np.unique(yhat,return_counts=True)\n",
    "        count_max = ccs.max()\n",
    "        print(f'\\nn{n_clusters} len{len(center_list)} clustering......{yhat} len{len(yhat)}......n{len(np.unique(yhat))}......{count_max}')\n",
    "\n",
    "    outfig_file = f'../plots/{axis}{level}u{uint}regions_n{n_clusters}cluster.png'\n",
    "    plot_axis_cluster(axis,yhat,region_list,center_list,outfig_file)\n",
    "    \n",
    "    clusters_list = []\n",
    "    for ilabel,label in enumerate(np.unique(yhat)):\n",
    "        cluster = np.array(region_list)[np.array(yhat)==label].tolist()\n",
    "        clusters_list.append([r for r in region_list2 if r in cluster])\n",
    "\n",
    "    return region_list,region_list2,clusters_list\n",
    "\n",
    "def plot_axis_cluster(axis,yhat,region_list,center_list,outfig_file):    \n",
    "    n_clusters = len(np.unique(yhat))\n",
    "    cs = 'brgcmyk'\n",
    "    k = int(np.ceil(n_clusters / len(cs)))\n",
    "    color = [c for c in (cs * k)[:n_clusters]]\n",
    "    fig = plt.figure(figsize=(math.ceil(n_clusters/10),1)) \n",
    "    xlims = [(0,528),(0,320),(0,456)][['AP','DV','RL'].index(axis)]\n",
    "    plt.xlim(xlims)\n",
    "    label_list = []\n",
    "    for i,label in enumerate(yhat):\n",
    "        point = center_list[i]\n",
    "        if not label in label_list: \n",
    "            if len(label_list): \n",
    "                plt.scatter(x=np.array(tmp), y=0 * np.array(tmp), s=2, c=color[len(label_list)])  \n",
    "            label_list.append(label)\n",
    "            tmp = [point]\n",
    "        else:\n",
    "            tmp.append(point)        \n",
    "    plt.savefig(outfig_file,dpi=600)\n",
    "    plt.close()\n",
    "    \n",
    "    \n",
    "level = 316\n",
    "uint = 32\n",
    "axis = 'AP'\n",
    "n_clusters = 40\n",
    "regions_list, regions_list2, regions_cluster = get_region_range_and_region_cluster(level,uint,axis,n_clusters)\n",
    "# regions_name_list = get_region_name_list(regions_list,uint)\n",
    "# regions_name_cluster = [get_region_name_list(cluster,uint) for cluster in regions_cluster]\n",
    "for i in ['GPi','VTA','PPN']:#从上到下 从左到右\n",
    "    print(i,get_region_name_list(regions_list,32).index(i),get_region_name_list(regions_list2,32).index(i),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 plot graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'white', 512: 'yellow', 623: 'blue', 688: 'red', 343: 'green'}\n",
      "['CB', 'CNU', 'CTX', 'BS']\n",
      "0 ['MOB'] ['AOB']\n",
      "1 ['AOB'] ['FRP']\n",
      "2 ['FRP'] ['AON', 'ORBm', 'ORBvl']\n",
      "3 ['AON', 'ORBm', 'ORBvl'] ['ORBl']\n",
      "4 ['ORBl'] ['PL']\n",
      "5 ['PL'] ['TT']\n",
      "6 ['TT'] ['AId', 'ILA']\n",
      "7 ['AId', 'ILA'] ['MOs', 'DP']\n",
      "8 ['MOs', 'DP'] ['AIv']\n",
      "9 ['AIv'] ['SH', 'MOp', 'ACB']\n",
      "10 ['SH', 'MOp', 'ACB'] ['ACAd', 'OT']\n",
      "11 ['ACAd', 'OT'] ['CLA', 'GU', 'SSp-m']\n",
      "12 ['CLA', 'GU', 'SSp-m'] ['IG', 'MS', 'ACAv', 'NDB', 'LSr', 'LSv']\n",
      "13 ['IG', 'MS', 'ACAv', 'NDB', 'LSr', 'LSv'] ['ADP', 'OV', 'PS', 'SI', 'AVPV', 'AVP']\n",
      "14 ['ADP', 'OV', 'PS', 'SI', 'AVPV', 'AVP'] ['MEPO']\n",
      "15 ['MEPO'] ['FS', 'MPO', 'VMPO', 'PVpo', 'LSc', 'MA', 'BST', 'CP', 'TRS', 'MPN', 'LPO', 'SSp-ul', 'VLPO', 'SF', 'BAC', 'PD']\n",
      "16 ['FS', 'MPO', 'VMPO', 'PVpo', 'LSc', 'MA', 'BST', 'CP', 'TRS', 'MPN', 'LPO', 'SSp-ul', 'VLPO', 'SF', 'BAC', 'PD'] ['EPd', 'SSp-n', 'PIR', 'AAA']\n",
      "17 ['EPd', 'SSp-n', 'PIR', 'AAA'] ['PVa', 'ASO', 'AD', 'SSs', 'RCH', 'PT', 'SSp-ll', 'AM', 'NLOT', 'SSp-un', 'SCH', 'PVH', 'SBPV', 'AV', 'IAD', 'AHN', 'AIp', 'SFO', 'GPe', 'SO']\n",
      "18 ['PVa', 'ASO', 'AD', 'SSs', 'RCH', 'PT', 'SSp-ll', 'AM', 'NLOT', 'SSp-un', 'SCH', 'PVH', 'SBPV', 'AV', 'IAD', 'AHN', 'AIp', 'SFO', 'GPe', 'SO'] ['BA', 'IA', 'CL', 'VISC', 'VPL', 'GPi', 'VAL', 'IAM', 'Xi', 'PR', 'SSp-bfd', 'CEA', 'LD', 'PVHd', 'LHA', 'TU', 'RH', 'MH', 'PVi', 'MD', 'RT', 'SSp-tr', 'PAA', 'EPv', 'SMT', 'PVT', 'RE', 'CM', 'VMH', 'VM', 'COAa', 'MEA', 'PCN', 'PeF']\n",
      "19 ['BA', 'IA', 'CL', 'VISC', 'VPL', 'GPi', 'VAL', 'IAM', 'Xi', 'PR', 'SSp-bfd', 'CEA', 'LD', 'PVHd', 'LHA', 'TU', 'RH', 'MH', 'PVi', 'MD', 'RT', 'SSp-tr', 'PAA', 'EPv', 'SMT', 'PVT', 'RE', 'CM', 'VMH', 'VM', 'COAa', 'MEA', 'PCN', 'PeF'] ['PST', 'IMD', 'LH', 'ARH', 'VPM', 'BMA', 'DMH']\n",
      "20 ['PST', 'IMD', 'LH', 'ARH', 'VPM', 'BMA', 'DMH'] ['BLA', 'PO', 'VISa', 'ZI', 'ME', 'VPMpc', 'FC', 'STN', 'LA']\n",
      "21 ['BLA', 'PO', 'VISa', 'ZI', 'ME', 'VPMpc', 'FC', 'STN', 'LA'] ['CA2', 'LGd', 'PSTN', 'AUDd', 'TMv', 'SPA', 'PMd', 'PMv', 'PH', 'CA3', 'PVp', 'VPLpc', 'VISam', 'LP', 'SPFm', 'PF', 'TMd', 'LGv', 'IGL', 'SubG']\n",
      "22 ['CA2', 'LGd', 'PSTN', 'AUDd', 'TMv', 'SPA', 'PMd', 'PMv', 'PH', 'CA3', 'PVp', 'VPLpc', 'VISam', 'LP', 'SPFm', 'PF', 'TMd', 'LGv', 'IGL', 'SubG'] ['VISal', 'AUDv', 'AUDpo', 'TEa', 'LM', 'AUDp', 'PIL', 'SPFp', 'MT', 'OP', 'SGN', 'PA', 'SUM', 'PERI', 'TR', 'RSPd', 'APN', 'RSPagl', 'VISrl', 'NOT', 'RSPv', 'COAp', 'MM', 'VTA', 'ECT', 'DG', 'SCO', 'SNr', 'CA1', 'MPT', 'NPC', 'MA3', 'VISpm', 'PPT', 'MG', 'PoT', 'POL', 'SNc', 'PP', 'LT', 'IntG']\n",
      "23 ['VISal', 'AUDv', 'AUDpo', 'TEa', 'LM', 'AUDp', 'PIL', 'SPFp', 'MT', 'OP', 'SGN', 'PA', 'SUM', 'PERI', 'TR', 'RSPd', 'APN', 'RSPagl', 'VISrl', 'NOT', 'RSPv', 'COAp', 'MM', 'VTA', 'ECT', 'DG', 'SCO', 'SNr', 'CA1', 'MPT', 'NPC', 'MA3', 'VISpm', 'PPT', 'MG', 'PoT', 'POL', 'SNc', 'PP', 'LT', 'IntG'] ['DT', 'IF', 'IPN', 'RL', 'RN', 'PN', 'EW']\n",
      "24 ['DT', 'IF', 'IPN', 'RL', 'RN', 'PN', 'EW'] ['HATA']\n",
      "25 ['HATA'] ['CLI', 'VISp', 'VISl', 'SCs', 'MRN', 'ProS', 'POST', 'PG', 'SCm', 'VISli', 'RR', 'ENTl', 'III', 'SUB', 'NB']\n",
      "26 ['CLI', 'VISp', 'VISl', 'SCs', 'MRN', 'ProS', 'POST', 'PG', 'SCm', 'VISli', 'RR', 'ENTl', 'III', 'SUB', 'NB'] ['PBG', 'AT', 'TRN', 'PAG', 'PRNr', 'CS', 'PRE', 'VISpor', 'NLL', 'Pa4', 'SAG', 'IV']\n",
      "27 ['PBG', 'AT', 'TRN', 'PAG', 'PRNr', 'CS', 'PRE', 'VISpor', 'NLL', 'Pa4', 'SAG', 'IV'] ['PAR', 'ENTm', 'PPN', 'DR', 'APr']\n",
      "28 ['PAR', 'ENTm', 'PPN', 'DR', 'APr'] ['PC5', 'VISpl', 'SUT', 'SOC', 'NTB', 'CUN', 'VTN', 'P5']\n",
      "29 ['PC5', 'VISpl', 'SUT', 'SOC', 'NTB', 'CUN', 'VTN', 'P5'] ['Acs5', 'V', 'PRNc', 'RPO', 'PSV']\n",
      "30 ['Acs5', 'V', 'PRNc', 'RPO', 'PSV'] ['I5', 'LDT', 'IC', 'PB', 'DTN']\n",
      "31 ['I5', 'LDT', 'IC', 'PB', 'DTN'] ['MEV', 'LC', 'VCO', 'SLD', 'ACVII', 'PCG', 'PDTg', 'VI', 'NI', 'RM', 'FL', 'SLC', 'B']\n",
      "32 ['MEV', 'LC', 'VCO', 'SLD', 'ACVII', 'PCG', 'PDTg', 'VI', 'NI', 'RM', 'FL', 'SLC', 'B'] ['PPY', 'VII', 'SG']\n",
      "33 ['PPY', 'VII', 'SG'] ['CENT']\n",
      "34 ['CENT'] ['ICB', 'PARN', 'DCO', 'VeCB', 'SUV', 'LING', 'MV', 'GRN', 'ISN', 'PRP', 'CUL', 'MARN', 'IP', 'PGRNd', 'SIM', 'DN', 'PFL', 'LAV', 'SPVO', 'y']\n",
      "35 ['ICB', 'PARN', 'DCO', 'VeCB', 'SUV', 'LING', 'MV', 'GRN', 'ISN', 'PRP', 'CUL', 'MARN', 'IP', 'PGRNd', 'SIM', 'DN', 'PFL', 'LAV', 'SPVO', 'y'] ['x', 'FN', 'IRN', 'RPA', 'PGRNl', 'SPIV']\n",
      "36 ['x', 'FN', 'IRN', 'RPA', 'PGRNl', 'SPIV'] ['RO', 'LIN', 'AMB', 'AN', 'NOD']\n",
      "37 ['RO', 'LIN', 'AMB', 'AN', 'NOD'] ['IO']\n",
      "38 ['IO'] ['SPVI']\n",
      "39 ['SPVI'] ['NTS']\n",
      "40 ['NTS'] ['PAS', 'XII', 'DEC', 'COPY', 'ECU', 'LRN', 'DMX', 'NR', 'PRM', 'Pa5']\n",
      "41 ['PAS', 'XII', 'DEC', 'COPY', 'ECU', 'LRN', 'DMX', 'NR', 'PRM', 'Pa5'] ['AP', 'UVU']\n",
      "42 ['AP', 'UVU'] ['SPVC', 'CU', 'MDRNv', 'PYR', 'FOTU', 'MDRNd', 'GR']\n"
     ]
    }
   ],
   "source": [
    "from utils import get_n1327_n4_u32dict\n",
    "regions_structure_dict = color_map(get_n1327_n4_u32dict(),\n",
    "                                   colors=['white','yellow','blue','red','green'])\n",
    "                                   #colors=['white','pink','gold','skyblue','green'])\n",
    "print(get_region_name_list([512,623,688,343],32))\n",
    "\n",
    "level = 316\n",
    "uint = 32\n",
    "regions_neighbor_dict = get_dict(level,uint,key='neighbor')   \n",
    "\n",
    "G = nx.DiGraph()\n",
    "for i,region_list in enumerate(regions_cluster[:-1]):\n",
    "    regions_name_list = get_region_name_list(region_list,uint)\n",
    "    if not i: \n",
    "        for n,r in zip(regions_name_list,region_list): \n",
    "            color = regions_structure_dict[r]\n",
    "            if color=='white': print(f'\\n{n} not in structure');continue\n",
    "            if n in regions_module_dict.keys():\n",
    "                fillcolor = regions_module_dict[n]\n",
    "                penwidth = 10\n",
    "            else: \n",
    "                fillcolor = 'white'\n",
    "                penwidth = 10\n",
    "            G.add_node(n,height=2,width=3.5,fontsize=80,style='filled',\n",
    "                       color=color,fillcolor=fillcolor,penwidth=penwidth)\n",
    "            \n",
    "    next_cluster = regions_cluster[i+1]\n",
    "    next_cluster_regions_name = get_region_name_list(next_cluster,uint)\n",
    "    for n,r in zip(next_cluster_regions_name,next_cluster):\n",
    "        color = regions_structure_dict[r]\n",
    "        if color=='white': continue\n",
    "        if n in regions_module_dict.keys():\n",
    "            fillcolor = regions_module_dict[n]\n",
    "            penwidth = 10\n",
    "        else: \n",
    "            fillcolor = 'white'\n",
    "            penwidth = 10\n",
    "        G.add_node(n,height=2,width=3.5,fontsize=80,style='filled',\n",
    "                   color=color,fillcolor=fillcolor,penwidth=penwidth)\n",
    "    print(i,regions_name_list,next_cluster_regions_name)\n",
    "    \n",
    "    for region,region_name in zip(region_list,regions_name_list):\n",
    "        if region_name not in G.nodes: continue\n",
    "        for n,r in zip(next_cluster_regions_name,next_cluster):\n",
    "            if n not in G.nodes: continue\n",
    "            if r in regions_neighbor_dict[region]:\n",
    "                G.add_edge(region_name, n, color='black', penwidth=10, arrowsize=0)\n",
    "            else:\n",
    "                G.add_edge(region_name, n, color='white', penwidth=0, arrowsize=0)\n",
    "\n",
    "TR = nx.nx_agraph.to_agraph(G)\n",
    "TR.draw(\"../plots/graph.pdf\", prog='dot')\n",
    "\n",
    "#TR.draw(\"../plots/graph15.pdf\", prog='dot')\n",
    "\n",
    "# TR.graph['label'] = f'\\n{cur_label}'\n",
    "# nodes = TR.nodes\n",
    "# nodes[rname]['penwidth'] = pw\n",
    "# nodes[rname]['fillcolor'] = color\n",
    "# nodes[rname]['style'] = 'filled'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 plot corr graphviz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 33 ['PC5', 'MARN', 'DMX', 'PRP', 'AMB', 'PPY', 'RPA', 'EW', 'Pa4', 'IV', 'MA3', 'CLI', 'DR', 'RPO', 'V', 'VTN', 'AT', 'LT', 'SLC', 'CS', 'GPi', 'VTA', 'PPN', 'PSTN', 'RT', 'ZI', 'PeF', 'TU', 'SPA', 'ME', 'PN', 'III', 'MRN']\n",
      "\n",
      " GPi \n",
      "high corr:  ['AId', 'AIp', 'AIv', 'MRN', 'LPO', 'LSv', 'MA', 'BST', 'CEA', 'TU', 'VISC', 'VM', 'VPLpc', 'DG', 'VPMpc', 'VTA', 'OT', 'ZI', 'EPv', 'FS', 'GPi', 'PPN', 'GU', 'IA', 'ME', 'PN']\n",
      "not in module: ['AId', 'AIv', 'OT', 'GU', 'LSv', 'FS', 'MA', 'BST', 'LPO', 'AIp', 'IA', 'VISC', 'CEA', 'EPv', 'VM', 'VPMpc', 'VPLpc', 'DG']\n",
      "high corr and in module: ['GPi', 'TU', 'ZI', 'ME', 'VTA', 'PN', 'MRN', 'PPN']\n",
      "0 node AId\n",
      "1 node AIv\n",
      "2 node OT\n",
      "3 node GU\n",
      "4 node LSv\n",
      "5 node FS\n",
      "5 node MA\n",
      "5 node BST\n",
      "5 node LPO\n",
      "6 node AIp\n",
      "7 node IA\n",
      "7 node VISC\n",
      "7 node GPi\n",
      "7 node CEA\n",
      "7 node TU\n",
      "7 node EPv\n",
      "7 node VM\n",
      "8 node ZI\n",
      "8 node ME\n",
      "8 node VPMpc\n",
      "9 node VPLpc\n",
      "10 node VTA\n",
      "10 node DG\n",
      "11 node PN\n",
      "12 node MRN\n",
      "13 node PPN\n",
      "\n",
      " VTA \n",
      "high corr:  ['III', 'ISN', 'AIp', 'MRN', 'LPO', 'RPO', 'RT', 'MA', 'CA3', 'CEA', 'SPA', 'TU', 'VISC', 'VTA', 'OT', 'ZI', 'PAS', 'EPv', 'GPi', 'PPN', 'GU', 'PRNc', 'IA', 'ME', 'PeF', 'PN']\n",
      "not in module: ['OT', 'GU', 'MA', 'LPO', 'AIp', 'IA', 'VISC', 'CEA', 'EPv', 'CA3', 'PRNc', 'ISN', 'PAS']\n",
      "high corr and in module: ['GPi', 'TU', 'RT', 'PeF', 'ZI', 'ME', 'SPA', 'VTA', 'PN', 'MRN', 'III', 'PPN', 'RPO']\n",
      "0 node OT\n",
      "1 node GU\n",
      "2 node MA\n",
      "2 node LPO\n",
      "3 node AIp\n",
      "4 node IA\n",
      "4 node VISC\n",
      "4 node GPi\n",
      "4 node CEA\n",
      "4 node TU\n",
      "4 node RT\n",
      "4 node EPv\n",
      "4 node PeF\n",
      "5 node ZI\n",
      "5 node ME\n",
      "6 node SPA\n",
      "6 node CA3\n",
      "7 node VTA\n",
      "8 node PN\n",
      "9 node MRN\n",
      "9 node III\n",
      "10 node PPN\n",
      "11 node PRNc\n",
      "11 node RPO\n",
      "12 node ISN\n",
      "13 node PAS\n",
      "\n",
      " PPN \n",
      "high corr:  ['III', 'ISN', 'MRN', 'LPO', 'RPO', 'RT', 'MA', 'SGN', 'CEA', 'SPA', 'TU', 'V', 'CS', 'VM', 'VTA', 'ZI', 'PAS', 'EPv', 'GPi', 'PPN', 'GU', 'PRNc', 'IA', 'ME', 'PeF', 'PN']\n",
      "not in module: ['GU', 'MA', 'LPO', 'IA', 'CEA', 'EPv', 'VM', 'SGN', 'PRNc', 'ISN', 'PAS']\n",
      "high corr and in module: ['GPi', 'TU', 'RT', 'PeF', 'ZI', 'ME', 'SPA', 'VTA', 'PN', 'MRN', 'III', 'CS', 'PPN', 'V', 'RPO']\n",
      "0 node GU\n",
      "1 node MA\n",
      "1 node LPO\n",
      "2 node IA\n",
      "2 node GPi\n",
      "2 node CEA\n",
      "2 node TU\n",
      "2 node RT\n",
      "2 node EPv\n",
      "2 node VM\n",
      "2 node PeF\n",
      "3 node ZI\n",
      "3 node ME\n",
      "4 node SPA\n",
      "5 node SGN\n",
      "5 node VTA\n",
      "6 node PN\n",
      "7 node MRN\n",
      "7 node III\n",
      "8 node CS\n",
      "9 node PPN\n",
      "10 node V\n",
      "10 node PRNc\n",
      "10 node RPO\n",
      "11 node ISN\n",
      "12 node PAS\n"
     ]
    }
   ],
   "source": [
    "from utils import load_json\n",
    "print('\\n',len(regions_module_dict.keys()),list(regions_module_dict.keys()))\n",
    "for region in ['GPi','VTA','PPN']:\n",
    "    corr_regions = load_json(f'../../assets/{region}.json')\n",
    "    print('\\n',region,'\\nhigh corr: ',corr_regions)\n",
    "    \n",
    "    new_regions_cluster = []\n",
    "    no_module = []\n",
    "    high_module = []\n",
    "    for cluster in regions_cluster:\n",
    "        cluster_name = get_region_name_list(cluster,32)\n",
    "        if len(set(cluster_name)&set(corr_regions)):\n",
    "            new_cluster = []\n",
    "            for ic,c in enumerate(cluster):\n",
    "                c_name = cluster_name[ic]\n",
    "                if c_name in corr_regions:\n",
    "                    new_cluster.append(c)\n",
    "                    if not c_name in list(regions_module_dict.keys()): no_module.append(c_name)\n",
    "                    else:high_module.append(c_name)                   \n",
    "            new_regions_cluster.append(new_cluster)\n",
    "    print(f'not in module: {no_module}')\n",
    "    print(f'high corr and in module: {high_module}')\n",
    "    \n",
    "    G = nx.DiGraph()\n",
    "    for i,region_list in enumerate(new_regions_cluster[:-1]):\n",
    "        regions_name_list = get_region_name_list(region_list,uint)\n",
    "        if not i:  \n",
    "            for n,r in zip(regions_name_list,region_list): \n",
    "                color = regions_structure_dict[r]\n",
    "                if color=='white': print(f'\\n{n} not in structure');continue\n",
    "                if n in regions_module_dict.keys():\n",
    "                    fillcolor = regions_module_dict[n]\n",
    "                    penwidth = 10\n",
    "                else: \n",
    "                    fillcolor = 'white'\n",
    "                    penwidth = 10\n",
    "                G.add_node(n,height=2,width=3.5,fontsize=80,style='filled',\n",
    "                           color=color,fillcolor=fillcolor,penwidth=penwidth)\n",
    "                print(f'{i} node {n}')\n",
    "                    \n",
    "        next_cluster = new_regions_cluster[i+1]\n",
    "        next_cluster_regions_name = get_region_name_list(next_cluster,uint)             \n",
    "        for n,r in zip(next_cluster_regions_name,next_cluster):\n",
    "            color = regions_structure_dict[r]\n",
    "            if color=='white': continue\n",
    "            if n in regions_module_dict.keys():\n",
    "                fillcolor = regions_module_dict[n]\n",
    "                penwidth = 10\n",
    "            else: \n",
    "                fillcolor = 'white'\n",
    "                penwidth = 10\n",
    "            G.add_node(n,height=2,width=3.5,fontsize=80,style='filled',\n",
    "                       color=color,fillcolor=fillcolor,penwidth=penwidth)\n",
    "            print(f'{i+1} node {n}')\n",
    "\n",
    "        for r,region_name in zip(region_list,regions_name_list):\n",
    "            if region_name not in G.nodes: continue\n",
    "            for n,r in zip(next_cluster_regions_name,next_cluster):\n",
    "                if n not in G.nodes: continue\n",
    "                if r in regions_neighbor_dict[r]:\n",
    "                    G.add_edge(region_name, n, color='black', penwidth=10, arrowsize=0)\n",
    "                    print(f'edge [{region_name}, {n}]')\n",
    "                else:\n",
    "                    G.add_edge(region_name, n, color='white', penwidth=0, arrowsize=0)\n",
    "\n",
    "    TR = nx.nx_agraph.to_agraph(G)\n",
    "    TR.draw(f\"../plots/{region}.pdf\", prog='dot')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function to manage data to axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_comp_acronym_data(df_labels,Id,Acronym,allow0,axis_id_list_dict,axis_acronym_list_dict):      \n",
    "    Id_tree = get_tree_from('u16_id')\n",
    "    Id_number = [Id_tree[v][Id] for v in df_labels['n671_u16_id']]  \n",
    "    Id_number = [Id_tree[v][Id] for v in df_labels['n671_u16_id']]  \n",
    "    #print(len(Id_number),len(np.unique(Id_number)))\n",
    "    Id_count = df_labels['count'].values \n",
    "    tree = get_tree_from(Id)\n",
    "    Id_list =  list(tree.keys())\n",
    "    #print(len(Id_list),len(np.unique(Id_list)))\n",
    "    Id_list_count = [Id_count[np.array(Id_number)==i].sum() for i in Id_list]       \n",
    "    \n",
    "    sorted_Id_count_index = sorted(range(len(Id_list_count)), key = lambda x:Id_list_count[x], reverse=True)\n",
    "    sorted_Id_count = [Id_list_count[i] for i in sorted_Id_count_index]\n",
    "    sorted_Id_list = [Id_list[i] for i in sorted_Id_count_index]    \n",
    "\n",
    "    #axis range\n",
    "    axis_data_dict = {}\n",
    "    for axis in ['AP','DV','RL']:  \n",
    "        axis_id_list = axis_id_list_dict[axis]\n",
    "        new_data = []\n",
    "\n",
    "        #brain range\n",
    "        brain_todel = []\n",
    "        for brain in df_labels['brain']: \n",
    "            if brain in brain_todel: continue\n",
    "            brain_todel.append(brain)\n",
    "\n",
    "            df_brain = df_labels[df_labels['brain']==brain]\n",
    "            if len(df_brain):\n",
    "                brain_Id_list = [Id_tree[v][Id] for v in df_brain['n671_u16_id']]   \n",
    "                brain_Id_count = df_brain['count'].values \n",
    "                if not allow0:\n",
    "                    for i in axis_id_list:\n",
    "                        comp = sorted_Id_list.index(i)\n",
    "                        acronym = Id_tree[i][Acronym]\n",
    "                        brain_i_count = brain_Id_count[np.array(brain_Id_list)==i].sum()   \n",
    "                        new_data.append([comp,acronym,i,brain_i_count,brain,df_brain['label'].values[0]])        \n",
    "\n",
    "        new_df_labels = pd.DataFrame(np.array(new_data),columns=['comp','acronym',Id,'count','brain','label'])#acronym顺序是axis顺序\n",
    "        axis_data_dict[axis] = new_df_labels\n",
    "    return axis_data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot labelled brain regional info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_labellingbrains_feature(df_labels,\n",
    "#                                  allow0,\n",
    "#                                  level,\n",
    "#                                  hemi,\n",
    "#                                  comp,\n",
    "#                                  outfig_dir,\n",
    "#                                  outfig_end,\n",
    "#                                ):\n",
    "    \n",
    "#     Level = f'in_n{level}'\n",
    "#     Id = 'u16_id' if hemi else 'u32_id'\n",
    "#     Acronym = f'acronym_lr' if hemi else f'acronym'\n",
    "#     Center = 'center_u25_lr' if hemi else 'center_u25'\n",
    "#     axis_id_list_dict, axis_acronym_list_dict = get_acronym_list(Level,Id,Acronym,Center)\n",
    "    \n",
    "#     Id = f'n{level}_u16_id' if hemi else f'n{level}_u32_id'\n",
    "#     Acronym = f'acronym_lr' if hemi else f'acronym'\n",
    "#     axis_comp_data_dict = get_comp_acronym_data(df_labels,Id,Acronym,allow0,axis_id_list_dict,axis_acronym_list_dict)\n",
    "    \n",
    "#     for axis in ['AP','DV','RL']: \n",
    "#         print(axis)  \n",
    "#         print(axis_id_list_dict[axis])\n",
    "#         print(axis_acronym_list_dict[axis])\n",
    "#         axis_data = axis_comp_data_dict[axis]\n",
    "#         axis_data_count = axis_data['count'].values.astype(int)\n",
    "#         axis_data['count'] = np.ceil(axis_data_count/axis_data_count.max()*20)/20\n",
    "#         axis_comp_data = axis_data[axis_data['comp'].apply(int)<=comp]\n",
    "#         print(axis_comp_data,'\\n')\n",
    "    \n",
    "#         cs = 'brgcmyk'\n",
    "#         nlabel = len(np.unique(axis_comp_data['label']))\n",
    "#         k = int(np.ceil(nlabel / len(cs)))\n",
    "#         palette = [c for c in (cs * k)[:nlabel]]\n",
    "        \n",
    "#         g = sns.relplot(\n",
    "#             data=axis_comp_data,\n",
    "#             x='acronym',\n",
    "#             y='brain',\n",
    "#             size='count',\n",
    "#             hue='label',\n",
    "#             height=20,\n",
    "#             aspect=1,\n",
    "#             sizes=(0,100),\n",
    "#             size_norm=(0,1),\n",
    "#             palette=palette,\n",
    "#         )        \n",
    "#         plt.xticks(fontsize=5,rotation=90)#axis_comp_data['acronym'].values\n",
    "#         plt.xlabel('')\n",
    "#         plt.yticks(labels=None, fontsize=5)\n",
    "#         plt.ylabel('Brain', fontsize=20)\n",
    "#         plt.grid(alpha=0.5)        \n",
    "#         outfig_compfile = f'{outfig_dir}/{axis}_n{level}_hemi{hemi}_comp{comp}_{outfig_end}'\n",
    "#         plt.savefig(outfig_compfile,dpi=300)\n",
    "#         plt.close()\n",
    "        \n",
    "#         print('\\n\\n')\n",
    "#     return axis_comp_data\n",
    "  \n",
    "    \n",
    "    \n",
    "# allow0 = False       \n",
    "# level = 316\n",
    "# hemi = True\n",
    "# comp = 200\n",
    "# outfig_dir = '../plots/labelling'\n",
    "# test = plot_labellingbrains_feature(df_labels = df_labels_signal,\n",
    "#                              allow0 = allow0,\n",
    "#                              level = level,\n",
    "#                              hemi = hemi,\n",
    "#                              comp = comp,\n",
    "#                              outfig_dir = outfig_dir,\n",
    "#                              outfig_end = 'signal.png'\n",
    "#                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allow0 = False       \n",
    "# level = 70\n",
    "# hemi = True\n",
    "# comp = 200\n",
    "# outfig_dir = '../plots/labelling'\n",
    "# plot_labellingbrains_feature(df_labels = df_labels_signal_new,\n",
    "#                              allow0 = allow0,\n",
    "#                              level = level,\n",
    "#                              hemi = hemi,\n",
    "#                              comp = comp,\n",
    "#                              outfig_dir = outfig_dir,\n",
    "#                              outfig_end = 'signal_new.png'\n",
    "#                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function to cluster regions along axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [t for t in get_new_tree() if np.isnan(t['center_25um_lr']).sum()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function to rerange data to certain order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerange(df,acronym_list,key='count'):\n",
    "    plot = []\n",
    "    for a,acronym in enumerate(acronym_list):\n",
    "        df_acronym = df[df['acronym']==acronym]\n",
    "        if a==0: brain = df_acronym['brain'].values\n",
    "        count = df_acronym[key].values.tolist()\n",
    "        plot.append(count)\n",
    "    #print(f'rerange acronym num: {len(plot)}, brain num: {len(plot[0])}')\n",
    "    plot = np.array(plot).T\n",
    "    df_plot = pd.DataFrame(plot,columns=acronym_list,index=brain,)\n",
    "    return df_plot\n",
    "\n",
    "\n",
    "def row_mean(df_brains,label_brain_dict):\n",
    "    labels_cols = df_brains.columns\n",
    "    labels_data = []\n",
    "    labels_index = []\n",
    "    for i,lbs in enumerate(label_brain_dict.items()):\n",
    "        l,bs = lbs\n",
    "        labels_index.append(l)\n",
    "        label_data = df_brains[[(int(b) in bs) for b in df_brains.index]].mean(axis=0).tolist()\n",
    "        labels_data.append(label_data)\n",
    "\n",
    "    df_labels = pd.DataFrame(labels_data,index=labels_index,columns=labels_cols)\n",
    "    return df_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# labels regional signal cluster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_labelling_correlation_clustermap(df_labels,label_brain_dict,\n",
    "#                                           level,hemi,Cluster,\n",
    "#                                           outfig_dir,outfig_end):\n",
    "#     Level = f'in_n{level}'\n",
    "#     Id = 'u16_id' if hemi else 'u32_id'\n",
    "#     Acronym = f'acronym_lr' if hemi else f'acronym'\n",
    "#     Center = 'center_u25_lr' if hemi else 'center_u25'\n",
    "#     axis_id_list_dict, axis_acronym_list_dict = get_acronym_list(Level,Id,Acronym,Center)\n",
    "\n",
    "#     Id = f'n{level}_u16_id' if hemi else f'n{level}_u32_id'\n",
    "#     Acronym = f'acronym_lr' if hemi else f'acronym'\n",
    "#     axis_comp_data_dict = get_comp_acronym_data(df_labels,Id,Acronym,allow0,axis_id_list_dict,axis_acronym_list_dict)\n",
    "    \n",
    "#     for axis in ['AP']:#,'DV','RL']: \n",
    "#         print(axis)  \n",
    "#         print(axis_id_list_dict[axis])\n",
    "#         print(axis_acronym_list_dict[axis])\n",
    "#         axis_data = axis_comp_data_dict[axis]\n",
    "#         axis_data['count'] = axis_data['count'].values.astype(int)\n",
    "#         print(axis_data,'\\n')\n",
    "    \n",
    "#         axis_acronym_list = axis_acronym_list_dict[axis]\n",
    "#         acronym_count = rerange(axis_data,axis_acronym_list)\n",
    "#         print(acronym_count,'\\n')\n",
    "        \n",
    "#         label_acronym_count = row_mean(acronym_count,label_brain_dict)\n",
    "#         label_acronym_count = pd.DataFrame(label_acronym_count.values.T,columns=label_acronym_count.index,index=label_acronym_count.columns)\n",
    "#         print(label_acronym_count,'\\n')\n",
    "       \n",
    "#         label_corr = label_acronym_count.corr()\n",
    "#         print(label_corr,'\\n')\n",
    "        \n",
    "# #         for i,label in enumerate(label_list):\n",
    "# #             print('\\n',i,label)\n",
    "# #             if label=='all': df_label = df_labels\n",
    "# #             else: df_label = df_labels[df_labels['label']==label]\n",
    "            \n",
    "#         palette = sns.color_palette(\"Greens\",n_colors=len(label_brain_dict))     \n",
    "            \n",
    "#         g = sns.clustermap(label_corr\n",
    "#         #            , norm=LogNorm(),\n",
    "#         #            , zscore=0#1\n",
    "#         #            , standard_scale=0#1       \n",
    "#         #            , mask=mask       #only show these true\n",
    "#                     , figsize=(20,20)\n",
    "#                     , cmap='coolwarm'\n",
    "#                     , cbar_pos=(0.01,0.05,0.02,0.15)#left bottom width height\n",
    "#                     , dendrogram_ratio=(.1,.2)\n",
    "#                     , row_cluster=Cluster\n",
    "#                     , row_colors=palette\n",
    "#                     , col_cluster=Cluster\n",
    "#                     , col_colors=palette\n",
    "#         #             , vmax=.3\n",
    "#         #             , vmin=.1\n",
    "#         #             , center=0.5\n",
    "#         #             , annot=True\n",
    "#         #             , xticklabels=True\n",
    "#         #             , yticklabels=True\n",
    "#         #             , square=True\n",
    "#                    )\n",
    "#         plt.xticks(fontsize=5,rotation=90)#axis_comp_data['acronym'].values\n",
    "#         plt.xlabel('')\n",
    "#         plt.yticks(labels=None, fontsize=5)\n",
    "#         plt.ylabel('')\n",
    "#         plt.grid(alpha=0.5)\n",
    "#         outfig_compfile = f'{outfig_dir}/{axis}_n{level}_hemi{hemi}_{Cluster}clusterlabel_{outfig_end}'\n",
    "#         plt.savefig(outfig_compfile,dpi=300)\n",
    "#         plt.close()\n",
    "\n",
    "#         print('\\n\\n')\n",
    "            \n",
    "#         #axis_acronym_list = g.data2d.columns\n",
    "            \n",
    "#     return label_corr\n",
    "             \n",
    "# level = 316\n",
    "# hemi = True\n",
    "# outfile_dir = '../data'\n",
    "# outfig_dir = '../plots/labelling'\n",
    "# for cluster in [False,True]:\n",
    "#     test = plot_labelling_correlation_clustermap(df_labels=df_labels_signal,\n",
    "#                                      label_brain_dict = labels_brains_dict,\n",
    "#                                      level=level,\n",
    "#                                      hemi=hemi,\n",
    "#                                      Cluster=cluster,\n",
    "#                                      outfig_dir = outfig_dir,\n",
    "#                                      outfig_end = 'signal.png'\n",
    "#                                      )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# level = 316\n",
    "# hemi = True\n",
    "# cluster = False\n",
    "# outfile_dir = '../data'\n",
    "# outfig_dir = '../plots/labelling'\n",
    "\n",
    "# for cluster in [False,True]:\n",
    "#     test = plot_labelling_correlation_clustermap(df_labels=df_labels_signal_new,\n",
    "#                                      label_brain_dict = labels_brains_dict_new,\n",
    "#                                      level=level,\n",
    "#                                      hemi=hemi,\n",
    "#                                      Cluster=cluster,\n",
    "#                                      outfig_dir = outfig_dir,\n",
    "#                                      outfig_end = 'signal_new.png'\n",
    "#                                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# region corr heatmap of one label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_acronym_correlation_heatmap(df_labels,level,hemi,\n",
    "#                                      comp,label_list,\n",
    "#                                      outfig_dir,outfig_end,\n",
    "#                                      clusters_dict):\n",
    "#     Level = f'in_n{level}'\n",
    "#     Id = 'u16_id' if hemi else 'u32_id'\n",
    "#     Acronym = f'acronym_lr' if hemi else f'acronym'\n",
    "#     Center = 'center_u25_lr' if hemi else 'center_u25'\n",
    "#     axis_id_list_dict, axis_acronym_list_dict = get_acronym_list(Level,Id,Acronym,Center)\n",
    "\n",
    "#     Id = f'n{level}_u16_id' if hemi else f'n{level}_u32_id'\n",
    "#     Acronym = f'acronym_lr' if hemi else f'acronym'\n",
    "#     for label in label_list:\n",
    "#         print(label,'\\n')\n",
    "#         if label=='all': df_label = df_labels\n",
    "#         else: df_label = df_labels[df_labels['label']==label]        \n",
    "#         axis_comp_data_dict = get_comp_acronym_data(df_label,Id,Acronym,allow0,axis_id_list_dict,axis_acronym_list_dict)\n",
    "\n",
    "#         for axis in ['AP','DV','RL']: \n",
    "#             print(axis)\n",
    "#             axis_acronym_list = axis_acronym_list_dict[axis]\n",
    "            \n",
    "#             axis_data = axis_comp_data_dict[axis]\n",
    "#             axis_data['count'] = axis_data['count'].values.astype(int)\n",
    "#             print(axis_data.shape,'\\n')\n",
    "#             axis_comp_data = axis_data[axis_data['comp'].apply(int)<=comp]\n",
    "#             print(axis_comp_data.shape,'\\n')\n",
    "        \n",
    "#             #acronym_count = axis_comp_data.pivot(index=['brain'],columns=['acronym'],values=['count'])\n",
    "#             acronym_count = rerange(axis_comp_data,axis_acronym_list)\n",
    "#             print(acronym_count.shape,'\\n')       \n",
    "#             acronym_corr = acronym_count.corr().fillna(0)  \n",
    "#             print(acronym_corr.shape,'\\n')\n",
    "            \n",
    "#             g,ax = plt.subplots(figsize=(60,60))\n",
    "#             sns.heatmap(acronym_corr\n",
    "#             #            ,mask=mask       #只显示为true的值\n",
    "#                         , cmap='coolwarm'\n",
    "#                         , cbar_kws={\"shrink\": 0.4}\n",
    "#             #             , vmax=.3\n",
    "#             #             , vmin=.1\n",
    "#             #             , center=0.5\n",
    "#             #             , annot=True\n",
    "#                         , xticklabels=True\n",
    "#                         , yticklabels=True\n",
    "#                         , square=True\n",
    "#                        )\n",
    "#             plt.xticks(fontsize=5,rotation=90)#axis_comp_data['acronym'].values\n",
    "#             plt.xlabel('')\n",
    "#             plt.yticks(labels=None, fontsize=5)\n",
    "#             plt.ylabel('')\n",
    "#             plt.grid(alpha=0.5)\n",
    "#             outfig_compfile = f'{outfig_dir}/{label}_{axis}_n{level}_hemi{hemi}_comp{comp}_corr_{outfig_end}'\n",
    "#             plt.savefig(outfig_compfile,dpi=300)\n",
    "#             plt.close()\n",
    "                       \n",
    "#             print('\\n\\n')            \n",
    "            \n",
    "\n",
    "\n",
    "# label_list = []\n",
    "# for i,l in enumerate(labels_brains_dict.items()):\n",
    "#     k,v = l\n",
    "#     if len(v)>5:\n",
    "#         print(i+1,k,len(v),'\\n')\n",
    "#         label_list.append(k)\n",
    "# label_list = ['all'] + label_list\n",
    "\n",
    "# level = 316\n",
    "# hemi = True\n",
    "# comp = 632\n",
    "# outfig_dir = '../plots/corr/n316_c632'\n",
    "# plot_acronym_correlation_heatmap(df_labels=df_labels_signal,\n",
    "#                                  level=level,\n",
    "#                                  hemi=hemi,\n",
    "#                                  comp=comp,\n",
    "#                                  label_list=label_list,\n",
    "#                                  outfig_dir = outfig_dir,\n",
    "#                                  outfig_end = 'signal.png',\n",
    "#                                  clusters_dict=clusters_dict,\n",
    "#                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_list = []\n",
    "# for i,l in enumerate(labels_brains_dict_new.items()):\n",
    "#     k,v = l\n",
    "#     if len(v)>5:\n",
    "#         print(i+1,k,len(v),'\\n')\n",
    "#         label_list.append(k)\n",
    "# label_list = ['all'] + label_list\n",
    "\n",
    "# level = 316\n",
    "# hemi = True\n",
    "# comp = 632\n",
    "# outfig_dir = '../plots/corr/n316_c632_new'\n",
    "# plot_acronym_correlation_heatmap(df_labels=df_labels_signal_new,\n",
    "#                                  level=level,\n",
    "#                                  hemi=hemi,\n",
    "#                                  comp=comp,\n",
    "#                                  label_list=label_list,\n",
    "#                                  outfig_dir = outfig_dir,\n",
    "#                                  outfig_end = 'signal_new.png',\n",
    "#                                  clusters_dict=clusters_dict,\n",
    "#                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 region corr clustermap of one label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acronym_correlation_clustermap(df_labels,level,hemi,\n",
    "                                     label_list,\n",
    "                                     outfig_dir,outfig_end,\n",
    "                                     clusters_dict):\n",
    "    Level = f'in_n{level}'\n",
    "    Id = 'u16_id' if hemi else 'u32_id'\n",
    "    Acronym = f'acronym_lr' if hemi else f'acronym'\n",
    "    Center = 'center_u25_lr' if hemi else 'center_u25'\n",
    "    axis_id_list_dict, axis_acronym_list_dict = get_acronym_list(Level,Id,Acronym,Center)\n",
    "    comp = 1000\n",
    "    \n",
    "    #cmap\n",
    "    cmap_dict = {}\n",
    "    for axis in ['AP','DV','RL']: \n",
    "        #print('\\n',axis)\n",
    "        axis_cluster_dict = clusters_dict[axis]\n",
    "        n_clusters = len(axis_cluster_dict)\n",
    "        #print(f'{n_clusters} clustering cmap\\n\\n')\n",
    "        cs = (sns.color_palette(\"Greys\",n_colors=n_clusters))\n",
    "        #print(len(cs),cs)\n",
    "        cmap = []\n",
    "        for nc,c in enumerate(axis_cluster_dict.items()):\n",
    "            k,v = c\n",
    "            for na in range(len(v)):\n",
    "                cmap.append(cs[nc])\n",
    "        cmap_dict[axis] = cmap\n",
    "    \n",
    "    Id = f'n{level}_u16_id' if hemi else f'n{level}_u32_id'\n",
    "    Acronym = f'acronym_lr' if hemi else f'acronym'  \n",
    "    for i,label in enumerate(label_list):\n",
    "        print('\\n',i,label)\n",
    "        if label=='all': df_label = df_labels\n",
    "        else: df_label = df_labels[df_labels['label']==label]\n",
    "            \n",
    "        axis_comp_data_dict = get_comp_acronym_data(df_label,Id,Acronym,allow0,axis_id_list_dict,axis_acronym_list_dict)    \n",
    "\n",
    "        for axis in ['AP']:#,'DV','RL']: \n",
    "            print('\\n',axis)\n",
    "            axis_data = axis_comp_data_dict[axis]\n",
    "            axis_comp_data = axis_data[axis_data['comp'].apply(int)<=comp]#comp\n",
    "            axis_comp_data['count'] = axis_comp_data['count'].values.astype(int)\n",
    "\n",
    "            if label=='all':\n",
    "                axis_acronym_list = axis_acronym_list_dict[axis]\n",
    "                acronym_count = rerange(axis_comp_data,axis_acronym_list)\n",
    "                Cluster = True\n",
    "                cmap = cmap_dict[axis]\n",
    "            else:\n",
    "                acronym_count = rerange(axis_comp_data,axis_acronym_list)\n",
    "                Cluster = False\n",
    "                cmap = cmap \n",
    "                print('\\n',axis_acronym_list,axis_comp_data.shape,acronym_count.shape)\n",
    "     \n",
    "            acronym_corr = acronym_count.corr().fillna(0)  \n",
    "            #print('\\n',acronym_corr)\n",
    "            \n",
    "            g = sns.clustermap(acronym_corr\n",
    "            #            , norm=LogNorm(),\n",
    "            #            , zscore=0#1\n",
    "            #            , standard_scale=0#1       \n",
    "            #            , mask=mask       #only show these true\n",
    "                        , figsize=(100,100)\n",
    "                        , cmap='coolwarm'\n",
    "                        , cbar_pos=(0.01,0.05,0.02,0.15)#left bottom width height\n",
    "                        , dendrogram_ratio=(.1,.2)\n",
    "                        , row_cluster=Cluster\n",
    "                        , row_colors=cmap\n",
    "                        , col_cluster=Cluster\n",
    "                        , col_colors=cmap\n",
    "            #             , vmax=.3\n",
    "            #             , vmin=.1\n",
    "            #             , center=0.5\n",
    "            #             , annot=True\n",
    "            #             , xticklabels=True\n",
    "            #             , yticklabels=True\n",
    "                        , square=True\n",
    "                       )\n",
    "            plt.xticks(fontsize=1,rotation=90)#axis_comp_data['acronym'].values\n",
    "            plt.xlabel('')\n",
    "            plt.yticks(labels=None, fontsize=1)\n",
    "            plt.ylabel('')\n",
    "            plt.grid(alpha=0.5)\n",
    "            outfig_compfile = f'{outfig_dir}/{label}_{axis}_n{level}_hemi{hemi}_comp{comp}_clustercorr_{outfig_end}'\n",
    "            plt.savefig(outfig_compfile,dpi=300)\n",
    "            plt.close()\n",
    "            \n",
    "            print('\\n\\n')\n",
    "            \n",
    "            if label=='all': \n",
    "                axis_acronym_list = axis_acronym_list.tolist()\n",
    "                acronym_index_list = [axis_acronym_list.index(a) for a in g.data2d.columns]                \n",
    "                cmap = [cmap[i] for i in acronym_index_list]\n",
    "                axis_acronym_list = g.data2d.columns\n",
    "                \n",
    "    return axis_acronym_list\n",
    "\n",
    "\n",
    "# level = 316\n",
    "# hemi = True\n",
    "# outfig_dir = '../plots/cluster_corr/n316'\n",
    "# label_list = []\n",
    "# for i,l in enumerate(labels_brains_dict.items()):\n",
    "#     k,v = l\n",
    "#     if len(v)>5:\n",
    "#         print(i+1,k,len(v),'\\n')\n",
    "#         label_list.append(k)\n",
    "# label_list = ['all'] + label_list\n",
    "\n",
    "# axis_acronym_list = plot_acronym_correlation_clustermap(df_labels=df_labels_signal,\n",
    "#                                      level=level,\n",
    "#                                      hemi=hemi,\n",
    "#                                      label_list=label_list,\n",
    "#                                      outfig_dir = outfig_dir,\n",
    "#                                      outfig_end = 'signal.png',\n",
    "#                                      clusters_dict=clusters_dict,\n",
    "#                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "level = 316\n",
    "hemi = False\n",
    "outfig_dir = '../plots/cluster_corr/n316_false'\n",
    "label_list = []\n",
    "for i,l in enumerate(labels_brains_dict_new.items()):\n",
    "    k,v = l\n",
    "    if len(v)>5:\n",
    "        print(i+1,k,len(v),'\\n')\n",
    "        label_list.append(k)\n",
    "label_list = ['all'] + label_list\n",
    "\n",
    "#NOTE\n",
    "label_list = ['all']\n",
    "\n",
    "axis_acronym_list_new = plot_acronym_correlation_clustermap(df_labels=df_labels_signal_new,\n",
    "                                     level=level,\n",
    "                                     hemi=hemi,\n",
    "                                     label_list=label_list,\n",
    "                                     outfig_dir = outfig_dir,\n",
    "                                     outfig_end = 'signal_new.png',\n",
    "                                     clusters_dict=clusters_dict,\n",
    "                                     )\n",
    "axis_acronym_list_new = axis_acronym_list_new.tolist()\n",
    "print(axis_acronym_list_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# projection mapped to row of level315 and hemi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_projection(projection_file,outfig,axis_acronym_list):\n",
    "    projection_csv = pd.read_csv(projection_file,index_col=0)\n",
    "    \n",
    "    acronym_lr_list = []\n",
    "    for a in projection_csv.columns:\n",
    "        acronym_lr = a.split('_',1)[1]+'_l' if a.startswith('ipsi') else a.split('_',1)[1]+'_r'\n",
    "        acronym_lr_list.append(acronym_lr)\n",
    "    projection_csv.columns = acronym_lr_list\n",
    "\n",
    "#     tree = get_tree()\n",
    "#     n316_u16_list = [t['acronym_lr'] for t in tree if t['in_n316']]\n",
    "#     rm = [i for i in acronym_lr_list if i not in n316_u16_list]\n",
    "#     print(rm)\n",
    "#     for r in rm:\n",
    "#         projection_csv = projection_csv.drop(projection_csv[projection_csv[r]>0].index)\n",
    "\n",
    "    #projection_csv = projection_csv.reset_index(drop=True)\n",
    "    \n",
    "    projection_csv = (projection_csv.T/projection_csv.sum(axis=1)).T.round(2)\n",
    "    \n",
    "    #col reraange\n",
    "    projection_csv_range = projection_csv[axis_acronym_list] #row rerange: sort_df_grade = df_grade.loc[sort_list]\n",
    "    g = sns.clustermap(projection_csv_range,row_cluster=True,col_cluster=False,cmap='coolwarm')#,center=-0.1)\n",
    "    plt.savefig(outfig+'.png')\n",
    "    plt.close()    \n",
    "    projection_csv_range = g.data2d\n",
    "    projection_csv_range.index= list(range(projection_csv_range.values.shape[0]))\n",
    "    \n",
    "#     for i in range(28):#74):\n",
    "#         begin = i*100+0\n",
    "#         end = i*100+100\n",
    "#         projection = projection_csv_range.iloc[begin:end]\n",
    "#         shape =  projection.values.shape\n",
    "#         projection.index= list(range(shape[0]))\n",
    "#         print('\\n',i,shape)#projection,'\\n')\n",
    "                \n",
    "#         fig,axes = plt.subplots(shape[0])\n",
    "#         for n,p in projection.iterrows():\n",
    "#             #print(n)\n",
    "#             img = np.array([(p.values)*255]).astype(np.uint8)#NOTE to use cmap\n",
    "#             img = np.tile(img,(int(shape[1]/shape[0]),1))\n",
    "#             img3d = np.expand_dims(img,axis=2).repeat(3,axis=2)\n",
    "#             axes[n].imshow(img,cmap='coolwarm')\n",
    "#             axes[n].set_xticks([])\n",
    "#             axes[n].set_yticks([])\n",
    "#             axes[n].axis('off')\n",
    "#             axes[n].set_ylabel(str(n))\n",
    "#         plt.gcf().subplots_adjust(left=None,top=None,bottom=None,right=None)\n",
    "#         outfig_file = outfig+'_'+str(i)+'.png'\n",
    "#         plt.savefig(outfig_file,dpi=600) \n",
    "#         plt.close()\n",
    "#         print(outfig_file)\n",
    "        \n",
    "    return projection_csv,projection_csv_range,\n",
    "    \n",
    "# projection_file = '../data/2743_Axon_Projection.csv'#NOTE should clac yourself later\n",
    "# outfig = '../plots/cluster_corr/projection.png'\n",
    "# test = plot_projection(projection_file,outfig,axis_acronym_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "projection_file = '../data/2743_Axon_Projection.csv'#NOTE should clac yourself later\n",
    "outfig = '../plots/cluster_corr/projection_new'\n",
    "test0,test1 = plot_projection(projection_file,outfig,axis_acronym_list_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_list = test0.index.tolist()\n",
    "projection_dict = {}\n",
    "for n,p in test1.iterrows():\n",
    "    #print(n,p)\n",
    "    nmax = p.max()\n",
    "    nindex = p.values.tolist().index(nmax)\n",
    "    npro = p[nindex-5:nindex+5]\n",
    "    isproindex = np.nonzero(npro.values>0)[0]\n",
    "    if len(isproindex)>2:\n",
    "        nneuron = neuron_list[n]\n",
    "        print(nneuron,nindex,' -5:+5 ',npro.values.tolist())\n",
    "        nacronym = npro.index.tolist()\n",
    "        print(nacronym,'\\n')\n",
    "        projection = str([nacronym[i] for i in isproindex])\n",
    "        if projection in projection_dict.keys():\n",
    "            projection_dict[projection].append(nneuron)\n",
    "        else: \n",
    "            projection_dict[projection] = [nneuron]\n",
    "print('\\n\\n\\n')\n",
    "for projection,pneuron in projection_dict.items():\n",
    "    pnum = len(pneuron)\n",
    "    print(projection,pneuron,pnum,'\\n')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for projection,pneuron in projection_dict.items():\n",
    "    if 'AUDp_l' in projection or 'AUDp_r' in projection:\n",
    "        pnum = len(pneuron)\n",
    "        print(projection,pneuron,pnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for projection,pneuron in projection_dict.items():\n",
    "    pnum = len(pneuron)\n",
    "    if 'POST_l' in projection or 'POST_r' in projection:\n",
    "            print(projection,pneuron,pnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for projection,pneuron in projection_dict.items():\n",
    "    pnum = len(pneuron)\n",
    "    if 'RSPv_l' in projection or 'RSPv_r' in projection:\n",
    "            print(projection,pneuron,pnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for projection,pneuron in projection_dict.items():\n",
    "    if 'MOs_l' in projection or 'MOs_r' in projection:\n",
    "        pnum = len(pneuron)\n",
    "        print(projection,pneuron,pnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for projection,pneuron in projection_dict.items():\n",
    "    if 'VM_l' in projection or 'VM_r' in projection:\n",
    "        pnum = len(pneuron)\n",
    "        print(projection,pneuron,pnum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 graphviz of one label without cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_colorcode(n_colors=7,cmap='Blues'):\n",
    "    cs = sns.color_palette(cmap,n_colors=n_colors)\n",
    "    new_cs = []\n",
    "    for c in cs:\n",
    "        new_c = [int(256*i) for i in c]\n",
    "        new_c_16 = '#'+''.join([hex(i)[2:].zfill(2) for i in new_c])\n",
    "        new_cs.append(new_c_16)\n",
    "    return new_cs\n",
    "\n",
    "def plot_graph_nx(acronym_plot,\n",
    "               neighbor_edge,\n",
    "               module_dict,\n",
    "               cmap,\n",
    "               method,\n",
    "               outdot_graphfile,\n",
    "               outfig_graphfile,\n",
    "               ):\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    node_list = list(acronym_plot.index)\n",
    "    nodesize_list = acronym_plot.values.astype('int').tolist()\n",
    "    nodefillcolor_list = [cmap[c] for c in nodesize_list]\n",
    "    G.add_nodes_from(node_list) \n",
    "    \n",
    "    edge_list = []\n",
    "    edgecolor_list = []\n",
    "    if neighbor_edge:\n",
    "        pass\n",
    "    else:\n",
    "        for i,ai in enumerate(node_list): \n",
    "            for aj in node_list[i+1:]:\n",
    "                edge_list.append((ai,aj))\n",
    "                edgecolor_list.append(module_dict[ai])\n",
    "    G.add_edges_from(edge_list) \n",
    "    write_dot(G,outdot_graphfile)\n",
    "    \n",
    "#     print(len(G.nodes),G.nodes,'\\n')\n",
    "#     print(len(G.edges),G.edges,'\\n')\n",
    "#     write_dot(G,outdot_graphfile)\n",
    "#     nx.draw(G,\n",
    "#             with_labels=True,\n",
    "#             font_size=2,\n",
    "#             font_color='black',\n",
    "#             arrowsize=2,\n",
    "#             pos = graphviz_layout(G,prog=method,),\n",
    "#             node_size=nodesize_list,\n",
    "#             node_color=nodefillcolor_list,\n",
    "#     #         cmap=plt.cm.Blues,\n",
    "#     #         vmin=round(min(plot_node_size)),\n",
    "#     #         vmax=round(max(plot_node_size)),\n",
    "#             edge_color=edgecolor_list,\n",
    "#     #         width=plot_edge_width,\n",
    "#            )\n",
    "#     plt.savefig(outfig_graphfile,dpi=600) \n",
    "           \n",
    "    TR = nx.transitive_reduction(G)   \n",
    "    TR.add_nodes_from(G.nodes(data=True))\n",
    "    TR.add_edges_from((u, v, G.edges[u, v]) for u, v in TR.edges)\n",
    "    print(len(TR.nodes),TR.nodes,'\\n')\n",
    "    print(len(TR.edges),TR.edges,'\\n')\n",
    "    \n",
    "    edge_list_new = TR.edges\n",
    "    edgecolor_list_new = [edgecolor_list[edge_list.index(e)] for e in edge_list_new ]\n",
    "    nx.draw(TR,\n",
    "            with_labels=True,\n",
    "            font_size=2,\n",
    "            font_color='black',\n",
    "            arrowsize=2,\n",
    "            pos = graphviz_layout(TR,prog=method,),\n",
    "            node_size=nodesize_list,\n",
    "            node_color=nodefillcolor_list,\n",
    "    #         cmap=plt.cm.Blues,\n",
    "    #         vmin=round(min(plot_node_size)),\n",
    "    #         vmax=round(max(plot_node_size)),\n",
    "            edge_color=edgecolor_list_new,\n",
    "    #         width=plot_edge_width,\n",
    "           )\n",
    "    plt.savefig(outfig_graphfile,dpi=600)    \n",
    "    \n",
    "    return G,TR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_graph_graphviz(acronym_plot,\n",
    "#                neighbor_edge,\n",
    "#                pattern_dict,\n",
    "#                cmap,\n",
    "#                method,\n",
    "#                outdot_graphfile,\n",
    "#                outfig_graphfile,\n",
    "#                ):\n",
    "#     G = Digraph()\n",
    "#     G.clear()\n",
    "#     G = Digraph('G', filename='cluster.gv', format='png',\n",
    "#                 engine=method,\n",
    "#                 node_attr={'width':'0.2','height':'0.8','fontsize':'20',},\n",
    "#                 graph_attr={'dpi':'300'},\n",
    "#                 #'cmap':'Blues',\n",
    "#                 )\n",
    "#     #g.graph_attr['dpi'] = '300'\n",
    "\n",
    "#     G.attr(compound='true',fontsize='10')\n",
    "    \n",
    "#     acronym_list = list(acronym_plot.index)\n",
    "#     for i,acronym in enumerate(acronym_list): \n",
    "#         comp = int(acronym_plot[acronym])\n",
    "#         G.node(name=acronym, \n",
    "#                label=acronym,#+'_  size_'+str(size),\n",
    "#                color=pattern_dict[acronym],\n",
    "#                style='filled',\n",
    "#                fillcolor=cmap[comp],\n",
    "#                       )\n",
    "    \n",
    "#     if neighbor_edge:\n",
    "#         pass\n",
    "#     else:\n",
    "#         for i,ai in enumerate(acronym_list): \n",
    "#             for aj in acronym_list[i+1:]:\n",
    "#                 G.edge(ai,aj,\n",
    "#                        color = pattern_dict[ai],\n",
    "#                        )\n",
    "    \n",
    "#     G.render(outfig_graphfile, view=True)          \n",
    "#     return G\n",
    "\n",
    "\n",
    "# G.save('../plots/graph/test.dot')   \n",
    "# G_ = nx.nx_agraph.read_dot('../plots/graph/test.dot')\n",
    "\n",
    "# TR = nx.nx_agraph.from_agraph(G)  # convert back to networkx (but as Graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calc_dist(xyz1,xyz2):\n",
    "    qsum = 0\n",
    "    for i in range(len(xyz1)):\n",
    "        qsum += (xyz1[i]-xyz2[i])**2\n",
    "    return math.sqrt(qsum)\n",
    "\n",
    "\n",
    "def plot_acronym_graph(df_labels,level,hemi,plot2,\n",
    "                       clusters_dict,\n",
    "                       module_dict,                        \n",
    "                       outfig_dir,outfig_end):\n",
    "    Level = f'in_n{level}'\n",
    "    Id = 'u16_id' if hemi else 'u32_id'\n",
    "    Acronym = f'acronym_lr' if hemi else f'acronym'\n",
    "    Center = 'center_u25_lr' if hemi else 'center_u25'\n",
    "    axis_id_list_dict, axis_acronym_list_dict = get_acronym_list(Level,Id,Acronym,Center)\n",
    " \n",
    "    if level==671: uplevel=316\n",
    "    if level==316: uplevel=70\n",
    "    if level==70: uplevel=5\n",
    "    UPLevelId = f'n{uplevel}_u16_id' if hemi else f'n{uplevel}_u32_id'\n",
    "    level_dict = {}\n",
    "    for t in get_new_tree():\n",
    "        if t[Level]:\n",
    "            level_dict[t[Acronym]] = t[UPLevelId]\n",
    "    print(len(level_dict),level_dict)\n",
    "    uplevel_list = np.unique(list(level_dict.values())).tolist()\n",
    "    level_num = len(uplevel_list)\n",
    "    print(level_num,uplevel_list)\n",
    "    levelmap = produce_colorcode(n_colors=level_num,cmap='Accent')\n",
    "    print(len(levelmap),levelmap)\n",
    "    level_map = dict(zip(uplevel_list,levelmap))\n",
    "    print(len(level_map),level_map)\n",
    "    \n",
    "    Id = f'n{level}_u16_id' if hemi else f'n{level}_u32_id'\n",
    "    Acronym = f'acronym_lr' if hemi else f'acronym'\n",
    "    axis_comp_data_dict = get_comp_acronym_data(df_labels,Id,Acronym,allow0,axis_id_list_dict,axis_acronym_list_dict)    \n",
    "        \n",
    "    for axis in ['AP']:#,'DV','RL']:\n",
    "        print('\\n')\n",
    "        axis_data = axis_comp_data_dict[axis]\n",
    "        axis_data = axis_data.astype({'comp': int})\n",
    "        axis_data = axis_data.astype({'count': int})\n",
    "        print(axis,'\\n',axis_data)\n",
    "        \n",
    "        axis_acronym_list = axis_acronym_list_dict[axis]\n",
    "        acronym_num = len(axis_acronym_list)\n",
    "        cmap = produce_colorcode(n_colors=acronym_num+1,cmap='Blues')\n",
    "        \n",
    "        axis_data = rerange(axis_data,axis_acronym_list,key=plot2)  \n",
    "        print(plot2,'\\n',axis_data)\n",
    "        if plot2=='count':    \n",
    "            agg = 'sum'\n",
    "            ex_str = f'axis_data.{agg}(axis=0)' \n",
    "            acronym_plot = eval(ex_str)  \n",
    "            acronym_plot = (acronym_plot/acronym_plot.max()*acronym_num).astype(int)            \n",
    "        if plot2=='comp':\n",
    "            acronym_plot = axis_data.iloc[0]\n",
    "        print(plot2,'\\n',acronym_plot) \n",
    "\n",
    "        cluster_dict = clusters_dict[axis]\n",
    "        axis2 = ['RL','AP','DV'][['AP','DV','RL'].index(axis)]\n",
    "        #['centerz','centerx','centery'][['AP','DV','RL'].index(axis)]\n",
    "        axis2_acronym_list = axis_acronym_list_dict[axis2]\n",
    "        print(axis2,'\\n',axis2_acronym_list)\n",
    "        cluster_dict_new = {}\n",
    "        for c,ca in cluster_dict.items():\n",
    "            ca_range = [axis2_acronym_list.tolist().index(a) for a in ca]\n",
    "            ca_range.sort(reverse=True)\n",
    "            cluster_dict_new[c] = [axis2_acronym_list[ia] for ia in ca_range]\n",
    "            print(c,ca,cluster_dict_new[c],)\n",
    "        print('\\n')\n",
    "        \n",
    "        method = 'dot'\n",
    "        neighbor_edge = False   \n",
    "        outfig_graphfile = f'{outfig_dir}/{plot2}_{axis}_n{level}_hemi{hemi}_edgeneigh{neighbor_edge}_graph_{method}_{outfig_end}'     \n",
    "        outdot_graphfile = f'{outfig_graphfile}.dot'  \n",
    "\n",
    "        G = plot_graph(acronym_plot,\n",
    "                       neighbor_edge,\n",
    "                       cluster_dict_new,\n",
    "                       module_dict,\n",
    "                       cmap,\n",
    "                       method,\n",
    "                       outdot_graphfile,outfig_graphfile)\n",
    "\n",
    "#         G = plot_graph_new(acronym_plot,\n",
    "#                        neighbor_edge,\n",
    "#                        cluster_dict_new,\n",
    "#                        module_dict,\n",
    "#                        level_dict,\n",
    "#                        level_map,\n",
    "#                        method,\n",
    "#                        outdot_graphfile,outfig_graphfile)\n",
    "        \n",
    "        return cluster_dict,axis2_acronym_list,G\n",
    "#     for a in brains_acronyms_count_df.columns:\n",
    "#         neighbor_id = acronym_tree[a][neighbor]\n",
    "#         neighbor_acronym = [id_tree[i][acronym] for i in neighbor_id]\n",
    "#         plot_tree[a] = {'neighbor':neighbor_acronym,\n",
    "#                         center:acronym_tree[a][center], \n",
    "#                         'count':int(brains_acronyms_count_df[a].mean()),\n",
    "#                         voxel:acronym_tree[a][voxel], \n",
    "#                         'rgb':acronym_tree[a]['rgb'],\n",
    "#                         'soma':len(np.nonzero((soma_acronym_df[acronym]==a).values)[0]),\n",
    "#                        } \n",
    "\n",
    "\n",
    "def plot_graph(acronym_plot,\n",
    "                       neighbor_edge,\n",
    "                       cluster_dict,\n",
    "                       module_dict,\n",
    "                       cmap,\n",
    "                       method,\n",
    "                       outdot_graphfile,outfig_graphfile):\n",
    "    node_list = list(acronym_plot.index)\n",
    "    nodesize_list = acronym_plot.values.astype('int').tolist()\n",
    "    nodefillcolor_list = [cmap[c] for c in nodesize_list]\n",
    "    #                fillcolor=cmap[comp],\n",
    "    \n",
    "    g = Digraph('G', filename='cluster.gv', format='pdf',\n",
    "                engine=method,\n",
    "                node_attr={'width':'0.2','height':'0.8','fontsize':'20',\n",
    "                           #'cmap':'Blues',\n",
    "                          },\n",
    "                #graph_attr={'dpi':'300'},\n",
    "               )\n",
    "#     g.graph_attr['dpi'] = '300'\n",
    "    g.attr(compound='true',fontsize='10')    \n",
    "\n",
    "    edges_cluster = []\n",
    "    edge_cluster = []\n",
    "    for ii,cca, in enumerate(cluster_dict.items()):\n",
    "        c,ca = cca\n",
    "        print('\\nsubgraph',c,ca)\n",
    "        with g.subgraph(name=f'cluster_{c}') as s:\n",
    "            s.attr(label=str(c),fontsize='20',fontcolor='black',style='dashed',\n",
    "                   #color='grey',rank='same',\n",
    "                  )\n",
    "            for node in ca: \n",
    "                if node in node_list:\n",
    "                    ica = node_list.index(node)\n",
    "                    nodesize = nodesize_list[ica]\n",
    "                    nodefillcolor = nodefillcolor_list[ica]\n",
    "#                     fillcolor = np.round(new_maps[sorted(nodes_color_list).index(color)],2) #信号密度\n",
    "#                     fillcolor = f'0.1,0.1,{fillcolor[2]}'\n",
    "                    nodecolor = module_dict[node]\n",
    "                    print(node,nodecolor,nodesize,nodefillcolor)\n",
    "                    s.node(name=node, \n",
    "                           label=node,\n",
    "                           color=nodecolor,\n",
    "                           style='filled',\n",
    "                           fillcolor=nodefillcolor,)\n",
    "                \n",
    "        if ii==0: \n",
    "            edge_cluster.append(str(c));edge_cluster.append(ca[int(len(ca)/2)])\n",
    "        else : \n",
    "            edge_cluster.append(str(c));edge_cluster.append(ca[int(len(ca)/2)])\n",
    "            print('cluster edge: ',edge_cluster)\n",
    "            edges_cluster.append(edge_cluster)\n",
    "            edge_cluster = [str(c),ca[int(len(ca)/2)]]\n",
    "\n",
    "        if neighbor_edge:    \n",
    "            print('neighbor developed')\n",
    "            \n",
    "        print('\\n')\n",
    "               \n",
    "    for i,edge in enumerate(edges_cluster):\n",
    "        g.edge(edge[1],edge[3],\n",
    "               lhead='cluster_'+edge[2],\n",
    "               ltail='cluster_'+edge[0],\n",
    "               len='2',\n",
    "               color = 'black',\n",
    "              )\n",
    "\n",
    "    #print(g.source)\n",
    "    g.render(outfig_graphfile,view=True)\n",
    "    return g\n",
    "\n",
    "\n",
    "def plot_graph_new(acronym_plot,\n",
    "                       neighbor_edge,\n",
    "                       cluster_dict,\n",
    "                       module_dict,\n",
    "                       level_dict,\n",
    "                       cmap,\n",
    "                       method,\n",
    "                       outdot_graphfile,outfig_graphfile):\n",
    "    node_list = list(acronym_plot.index)\n",
    "    nodesize_list = acronym_plot.values.astype('int').tolist()\n",
    "    nodefillcolor_list = [cmap[level_dict[c] ]for c in node_list]\n",
    "    \n",
    "    g = Digraph('G', filename='cluster.gv', format='pdf',\n",
    "                engine=method,\n",
    "                node_attr={'width':'0.2','height':'0.8','fontsize':'20',\n",
    "                           #'cmap':'Blues',\n",
    "                          },\n",
    "                #graph_attr={'dpi':'300'},\n",
    "               )\n",
    "#     g.graph_attr['dpi'] = '300'\n",
    "    g.attr(compound='true',fontsize='10')    \n",
    "\n",
    "    edges_cluster = []\n",
    "    edge_cluster = []\n",
    "    for ii,cca, in enumerate(cluster_dict.items()):\n",
    "        c,ca = cca\n",
    "        print('\\nsubgraph',c,ca)\n",
    "        with g.subgraph(name=f'cluster_{c}') as s:\n",
    "            s.attr(label=str(c),fontsize='20',fontcolor='black',style='dashed',\n",
    "                   #color='grey',rank='same',\n",
    "                  )\n",
    "            for node in ca: \n",
    "                if node in node_list:\n",
    "                    ica = node_list.index(node)\n",
    "                    nodesize = nodesize_list[ica]\n",
    "                    nodefillcolor = nodefillcolor_list[ica]\n",
    "#                     fillcolor = np.round(new_maps[sorted(nodes_color_list).index(color)],2) #信号密度\n",
    "#                     fillcolor = f'0.1,0.1,{fillcolor[2]}'\n",
    "                    nodecolor = module_dict[node]\n",
    "                    print(node,nodecolor,nodesize,nodefillcolor)\n",
    "                    s.node(name=node, \n",
    "                           label=node,\n",
    "                           color=nodecolor,\n",
    "                           style='filled',\n",
    "                           fillcolor=nodefillcolor,)\n",
    "                \n",
    "        if ii==0: \n",
    "            edge_cluster.append(str(c));edge_cluster.append(ca[int(len(ca)/2)])\n",
    "        else : \n",
    "            edge_cluster.append(str(c));edge_cluster.append(ca[int(len(ca)/2)])\n",
    "            print('cluster edge: ',edge_cluster)\n",
    "            edges_cluster.append(edge_cluster)\n",
    "            edge_cluster = [str(c),ca[int(len(ca)/2)]]\n",
    "\n",
    "        if neighbor_edge:    \n",
    "            print('neighbor developed')\n",
    "            \n",
    "        print('\\n')\n",
    "               \n",
    "    for i,edge in enumerate(edges_cluster):\n",
    "        g.edge(edge[1],edge[3],\n",
    "               lhead='cluster_'+edge[2],\n",
    "               ltail='cluster_'+edge[0],\n",
    "               len='2',\n",
    "               color = 'black',\n",
    "              )\n",
    "\n",
    "    #print(g.source)\n",
    "    g.render(outfig_graphfile,view=True)\n",
    "    return g\n",
    "\n",
    "\n",
    "\n",
    "module_dict = {}\n",
    "for a in axis_acronym_list_new: #NOTE test\n",
    "    module_dict[a] = 'black'\n",
    "    begin = axis_acronym_list_new.index('SNc_r')+2\n",
    "    end = axis_acronym_list_new.index('FOTU_r')-2\n",
    "    if a in axis_acronym_list_new[begin:end]: module_dict[a] = 'red'\n",
    "    begin = axis_acronym_list_new.index('AUDp_r')\n",
    "    end = axis_acronym_list_new.index('RSPv_l')+1        \n",
    "    if a in axis_acronym_list_new[begin:end]: module_dict[a] = 'olive'\n",
    "    begin = axis_acronym_list_new.index('MOs_l')\n",
    "    end = axis_acronym_list_new.index('AD_l')+1    \n",
    "    if a in axis_acronym_list_new[begin:end]: module_dict[a] = 'cyan'\n",
    "    begin = axis_acronym_list_new.index('COPY_r')\n",
    "    end = axis_acronym_list_new.index('XII_l')+1\n",
    "    if a in axis_acronym_list_new[begin:end]: module_dict[a] = 'orange'\n",
    "    begin = axis_acronym_list_new.index('SPIV_l')+1\n",
    "    end = axis_acronym_list_new.index('SSp-un_l')\n",
    "    if a in axis_acronym_list_new[begin:end]: module_dict[a] = 'green'\n",
    "    begin = axis_acronym_list_new.index('DT_l')+1\n",
    "    end = axis_acronym_list_new.index('AHN_r')\n",
    "    if a in axis_acronym_list_new[begin:end]: module_dict[a] = 'purple'\n",
    "    begin = axis_acronym_list_new.index('PIL_r')+1\n",
    "    end = axis_acronym_list_new.index('LDT_l')  \n",
    "    if a in axis_acronym_list_new[begin:end]: module_dict[a] = 'pink'\n",
    "    begin = axis_acronym_list_new.index('PP_r')\n",
    "    end = axis_acronym_list_new.index('MD_l')+1\n",
    "    if a in axis_acronym_list_new[begin:end]: module_dict[a] = 'yellow'\n",
    "\n",
    "level = 316\n",
    "hemi = False\n",
    "outfig_dir = '../plots/graph'\n",
    "outfig_end = 'signal'\n",
    "n_clusters = 20\n",
    "plot2 = 'count'\n",
    "test0,test1,test2 = plot_acronym_graph(df_labels_signal_new,\n",
    "                   level,hemi,plot2,\n",
    "                   clusters_dict,\n",
    "                   module_dict,\n",
    "                   outfig_dir,outfig_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(axis_acronym_list_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 get brain somata of n671 u16 region\n",
    "图b上图加一下labelling bar\n",
    "图b下图671*2好一些"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_brain_somata_df(annotation,\n",
    "#                     brain_path,):\n",
    "#     boxin_id = []\n",
    "    \n",
    "#     boxin_num = 0\n",
    "#     boxout_num = 0\n",
    "#     tree = parse_swc(brain_path)\n",
    "#     for leaf in tree:\n",
    "#         i,t,x,y,z,r,p = leaf\n",
    "#         try:\n",
    "#             ac = annotation[round(z),round(y),round(x),]  \n",
    "#             boxin_num += 1\n",
    "#             boxin_id.append(ac)\n",
    "#         except:\n",
    "#             boxout_num += 1\n",
    "#             continue\n",
    "#     print(brain_path,boxin_num,boxout_num,'\\n')\n",
    " \n",
    "#     brain_somata_df = pd.DataFrame(np.array(np.unique(boxin_id,return_counts=True)).T,columns=['n671_u16_id','count'])    \n",
    "#     return brain_somata_df\n",
    "    \n",
    "    \n",
    "# def get_brains_somata_df(brains,\n",
    "#                          annotation,\n",
    "#                          somata_dir,\n",
    "#                          allow0,):\n",
    "#     df_brains = pd.DataFrame([])\n",
    "    \n",
    "#     for brain in brains:\n",
    "#         brain_path = f'{somata_dir}/*/{brain}_*_stps.swc'\n",
    "#         try:\n",
    "#             brain_path = glob.glob(brain_path)[0]\n",
    "#             print(f'\\n{brain_path} appended')\n",
    "#             df_brain = get_brain_somata_df(annotation = annotation,\n",
    "#                                            brain_path = brain_path,)\n",
    "#         except:\n",
    "#             print(f'\\n{brain_path} does not exists')\n",
    "#             return df_brains \n",
    "        \n",
    "#         if not allow0:\n",
    "#             df_brain = df_brain[df_brain['n671_u16_id']!=0]\n",
    "    \n",
    "#         if len(df_brain):\n",
    "#             df_brain['brain'] = brain\n",
    "#             df_brains = pd.concat([df_brains,df_brain])\n",
    "#     return df_brains   \n",
    "\n",
    "\n",
    "# def get_labellingbrains_somata(labels_brains_dict,\n",
    "#                                maskfile,\n",
    "#                                somata_dir,\n",
    "#                                allow0,):\n",
    "#     annotation = sitk.GetArrayFromImage(sitk.ReadImage(maskfile))    \n",
    "\n",
    "#     df_labels = pd.DataFrame([])    \n",
    "#     for label,brains in labels_brains_dict.items():\n",
    "#         df_label = get_brains_somata_df(brains,\n",
    "#                                         annotation,\n",
    "#                                         somata_dir,\n",
    "#                                         allow0,)    \n",
    "#         if len(df_label):\n",
    "#             df_label['label'] = label\n",
    "#             df_labels = pd.concat([df_labels,df_label])\n",
    "#     return df_labels      \n",
    "\n",
    "\n",
    "\n",
    "# #fmost-zeng\n",
    "# #n671_u16_id\n",
    "# somata_dir = '../../fig1bstype/marker_regi_25'\n",
    "# maskfile = f'../../assets/n671_u16.nrrd'\n",
    "# df_labels_somata = get_labellingbrains_somata(labels_brains_dict = labels_brains_dict,\n",
    "#                                        maskfile = maskfile,\n",
    "#                                        somata_dir = somata_dir,\n",
    "#                                        allow0 = allow0,)  \n",
    "\n",
    "\n",
    "# df_labels_somata#acronym的顺序是数字大小的顺序"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = []\n",
    "# y = []\n",
    "# z = []\n",
    "# a = []\n",
    "# for k,v in plot_tree.items():\n",
    "#     x += [v['center_u25_lr'][0]]\n",
    "#     y += [v['center_u25_lr'][1]]\n",
    "#     z += [v['center_u25_lr'][2]]\n",
    "#     a += [k]\n",
    "# center_df = pd.DataFrame(np.array([x,y,z,a]).T,columns=['x','y','z','a'])\n",
    "\n",
    "# fig = px.scatter(x=x,y=z,)\n",
    "# fig.show()\n",
    "# center_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
